{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdmhrtzSGE3DphY5Vav5hI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocolovett/Spam-Emails-Classifier/blob/main/Spam_Emails_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spam Emails Classifer\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hFXW-4jzul9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This notebook has been built to differentiate between **spam** or **ham** emails. We can teach this model to recognise potentially spam emails, then add our own datasets to it to find new spam emails. This is an early step in automated detection of spam emails.*"
      ],
      "metadata": {
        "id": "eMsSdx1Duthh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DSlIKOf6vgho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries required for the notebook."
      ],
      "metadata": {
        "id": "0e4HJkbguJ2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import time\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "P_whdRS9t8gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*WordNetLimmatizer* and *stopwords* process the raw images in the dataset. The *sklearn* modules will be used during model building."
      ],
      "metadata": {
        "id": "lXd7ff3muTqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This step allows us to upload our dataset into the notebook/model\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "A1d6ZEZZwqPz",
        "outputId": "606ea513-8ddb-46c7-97ef-fd4059c20bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9bd3e25d-a215-490c-81d3-aae28460bad9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9bd3e25d-a215-490c-81d3-aae28460bad9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Spam Email raw text for NLP.csv to Spam Email raw text for NLP.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Spam Email raw text for NLP.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe for use throughout the model\n",
        "df.head()\n",
        "# This will display the first 5 rows of the dataset"
      ],
      "metadata": {
        "id": "2JYavbdcz1KE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "de98fb0c-babb-4fb1-9631-f66485639174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CATEGORY                                            MESSAGE  \\\n",
              "0         1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...   \n",
              "1         1  ATTENTION: This is a MUST for ALL Computer Use...   \n",
              "2         1  This is a multi-part message in MIME format.\\n...   \n",
              "3         1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...   \n",
              "4         1  This is the bottom line.  If you can GIVE AWAY...   \n",
              "\n",
              "                                FILE_NAME  \n",
              "0  00249.5f45607c1bffe89f60ba1ec9f878039a  \n",
              "1  00373.ebe8670ac56b04125c25100a36ab0510  \n",
              "2  00214.1367039e50dc6b7adb0f2aa8aba83216  \n",
              "3  00210.050ffd105bd4e006771ee63cabc59978  \n",
              "4  00033.9babb58d9298daa2963d4f514193d7d6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6bb4327-8d1e-4553-8336-4dcfbcac8014\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>FILE_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
              "      <td>00249.5f45607c1bffe89f60ba1ec9f878039a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
              "      <td>00373.ebe8670ac56b04125c25100a36ab0510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
              "      <td>00214.1367039e50dc6b7adb0f2aa8aba83216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
              "      <td>00210.050ffd105bd4e006771ee63cabc59978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
              "      <td>00033.9babb58d9298daa2963d4f514193d7d6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6bb4327-8d1e-4553-8336-4dcfbcac8014')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6bb4327-8d1e-4553-8336-4dcfbcac8014 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6bb4327-8d1e-4553-8336-4dcfbcac8014');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the first five rows of the dataset show a filename that either connected to the email, or any potential attachments. As we don't know what this refers to, we will class it as irrelevant and *drop* it."
      ],
      "metadata": {
        "id": "TW9Ylb2p1Uz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('FILE_NAME', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "mT91IxLc1rwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we would like to know how many emails we have in our dataset in total. This will help us later when we decide the size of our training dataset compared to our testing dataset."
      ],
      "metadata": {
        "id": "agfoCpdq13si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.CATEGORY.value_counts()"
      ],
      "metadata": {
        "id": "qr4iRvoi2Sru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5ded97-2dab-4904-fe09-9f72e3185523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3900\n",
              "1    1896\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we know the size of our dataset, we need to download 'stopwords' - these are commonly occurring words within the English language. Then, we're going to open WordNet, which is a database of English words and their semantic meanings. We're going to store them in a new variables to use later."
      ],
      "metadata": {
        "id": "BdVDku3b2sTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "hynbSDL43ATt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7713b56-2b3f-4dce-804b-39000c6d6bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "i1WaT7Go3mtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7f460d-1c04-4e4c-91e1-24879092af72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "# Lemmatization is a technique used in NLP to reduce derivational forms of words to their dictionary meaning\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "TU5ltHLD3vS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d0f9d5-026e-498a-f393-ad0787bf4131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model gets to work, we're going to need our preprocessed messages to be stored somewhere. So, we're going to create an empty list to store them."
      ],
      "metadata": {
        "id": "iUylKaXr4Ym3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]"
      ],
      "metadata": {
        "id": "hgi2nM0r4n0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the empty list, lets start filling it with the emails that have been processed to where the text has been converted. We need the model to do the following:\n",
        "\n",
        "\n",
        "*   remove all non-alphanumeric characters\n",
        "*   convert the text to lowercase\n",
        "*   split the text into words\n",
        "*   remove the stopwords and lemmatize the words\n",
        "*   convert the words back to sentences\n",
        "*   add the message to the corpus list\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Brz0T-Tk4waF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "    # remove all non-alphanumeric characters\n",
        "    message = re.sub('[^a-zA-Z0-9]', ' ', df['MESSAGE'][i])\n",
        "\n",
        "    # convert the text to lowercase\n",
        "    message = message.lower()\n",
        "\n",
        "    # split the text into words for lemmatization\n",
        "    message = message.split()\n",
        "\n",
        "    # remove stopwords and lemmatizing\n",
        "    message = [lemmatizer.lemmatize(word) for word in message\n",
        "             if word not in set(stopwords.words('english'))]\n",
        "\n",
        "    # Convert the words back into sentences\n",
        "    message = ' '.join(message)\n",
        "\n",
        "    # Add the message to the corpus list\n",
        "    corpus.append(message)"
      ],
      "metadata": {
        "id": "XKarpM1x4rAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we're going to ask the model to count how many times certain words appear throughout the dataset and provide it with a *weight*. This will provide the mdoel with a better understanding the meaning of the text."
      ],
      "metadata": {
        "id": "JrwGkKEQ_-g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = TfidfVectorizer(ngram_range=(1,3), max_features=2500)\n",
        "X = tf.fit_transform(corpus).toarray()\n",
        "y = df['CATEGORY']"
      ],
      "metadata": {
        "id": "mZvRpzTi__ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vCigN06H7nHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the fun stuff!"
      ],
      "metadata": {
        "id": "HUEC6BhMAJQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we've just *cleaned* our data. We've removed all the *and*s, *if*s, and *but*s from these emails, but we've not actually gotten to the part where we begin to teach the model. Now we need to tell the model that we need two seperate datasets - our training set and our test set. Our training set will *teach* the model, while the test set will, as you can guess, *test* the model to make sure it works as it should."
      ],
      "metadata": {
        "id": "DvvNtHed7opZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "  X, y, test_size=0.30, random_state=1, stratify=y)"
      ],
      "metadata": {
        "id": "u_XchRcg9vP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise a Naive Bayes model using the scikit-learn MultinomialNB class\n",
        "model = MultinomialNB()"
      ],
      "metadata": {
        "id": "wGSExl31Ag_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nowe we're going to apply or fit the training data to the model. This is where the model would read the messages and would also be able to read the classification."
      ],
      "metadata": {
        "id": "yJR8d5T3BTuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "kS5Kr8QuBeqL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "491db6b1-988a-47af-f38f-187af6b83605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the original dataset, each email was given a value or 0 or 1, with 1 being not spam, and 0 being spam. All of these emails have been evaluated by a person who has deemed them as such. This will be our baseline to understand whether the model works or not."
      ],
      "metadata": {
        "id": "DZ32TFneG1Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training and testing sets\n",
        "train_pred = model.predict(x_train)\n",
        "test_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "9PLlc09TBltb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're giving the test dataset to the model. Imagine that the model reads the dataset with the column containing the correct classifications is hidden until the model has given its own classifications. Once that's done, the model checks it's answers to provide an accuracy score."
      ],
      "metadata": {
        "id": "O3JmpYTsILhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(train_pred, y_train))\n",
        "print(classification_report(test_pred, y_test))"
      ],
      "metadata": {
        "id": "llJo73fJCBcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d65afa9-377a-480d-dd9a-bccb18361f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97      2855\n",
            "           1       0.89      0.98      0.94      1202\n",
            "\n",
            "    accuracy                           0.96      4057\n",
            "   macro avg       0.94      0.97      0.95      4057\n",
            "weighted avg       0.96      0.96      0.96      4057\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97      1221\n",
            "           1       0.90      0.98      0.94       518\n",
            "\n",
            "    accuracy                           0.96      1739\n",
            "   macro avg       0.94      0.97      0.96      1739\n",
            "weighted avg       0.96      0.96      0.96      1739\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK! So, now we know the model's accuracy, we can test it out. The next couple of sections have text that I've copied and pasted from a selection of emails that have come into my personal email inbox. Let's see how many spam emails I've received..."
      ],
      "metadata": {
        "id": "vSVI-68OE-XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicting... \\n')\n",
        "\n",
        "message = [\"Hello, You have been selected for the whitelist of our NFT drop.\"]\n",
        "\n",
        "message_vector = tf.transform(message)\n",
        "category = model.predict(message_vector)\n",
        "\n",
        "# pause for dramatic effect\n",
        "time.sleep(5)\n",
        "\n",
        "# print the outcome of the model's prediction\n",
        "print(\"The message is\", \"spam!\" if category == 1 else \"ham and not spam\")"
      ],
      "metadata": {
        "id": "YMVAYYgnCHI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3037a47e-90b7-4a66-e0c0-4cc027429355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting... \n",
            "\n",
            "The message is ham and not spam\n"
          ]
        }
      ]
    }
  ]
}